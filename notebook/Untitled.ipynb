{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfd5cde1-00c9-4d90-8b26-90f2da3c53fa",
   "metadata": {},
   "source": [
    "# Test Vari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "196b8d76-acbb-4b10-8368-68f997949f1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "import torch\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsChannelFirst,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    Resize\n",
    ")\n",
    "# from torch.utils.data import DataLoader\n",
    "from monai.data import DataLoader\n",
    "from monai.networks.nets import DenseNet121\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2ac8b1cd-0f51-4033-ab67-629a64a65cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dimensioni del dataset sono : \n",
      "Train 1132\n",
      "Validation 283\n",
      "Test 354\n"
     ]
    }
   ],
   "source": [
    "T1  = [\"/home/jovyan/Verdicchio/ONWAY_DATA/Dataset/T1/\" + x for x in os.listdir(\"/home/jovyan/Verdicchio/ONWAY_DATA/Dataset/T1/\")]\n",
    "T2  = [\"/home/jovyan/Verdicchio/ONWAY_DATA/Dataset/T2/\" + x for x in os.listdir(\"/home/jovyan/Verdicchio/ONWAY_DATA/Dataset/T2/\")]\n",
    "FLAIR  = [\"/home/jovyan/Verdicchio/ONWAY_DATA/Dataset/FLAIR/\" + x for x in os.listdir(\"/home/jovyan/Verdicchio/ONWAY_DATA/Dataset/FLAIR/\")]\n",
    "OTHER  = [\"/home/jovyan/Verdicchio/ONWAY_DATA/Dataset/OTHER/\" + x for x in os.listdir(\"/home/jovyan/Verdicchio/ONWAY_DATA/Dataset/OTHER/\")]\n",
    "\n",
    "\n",
    "X = T1 + T2 + FLAIR +OTHER \n",
    "y = list(np.zeros(len(T1),dtype = int)) + list(np.ones(len(T2),dtype = int)) + list(np.ones(len(FLAIR),dtype = int)) + list(3*np.ones(len(OTHER),dtype = int))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,shuffle=True ,random_state=42,stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2,shuffle=True ,random_state=42,stratify=y_train)\n",
    "\n",
    "print(\"Le dimensioni del dataset sono : \")\n",
    "print(f\"Train {len(X_train)}\")\n",
    "print(f\"Validation {len(X_val)}\")\n",
    "print(f\"Test {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "238fb4ff-3ad6-4ab1-a032-db24b44a5567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Sequence_Dataset(torch.utils.data.Dataset) : \n",
    "    def __init__(self,image_files, transforms): \n",
    "        self.image_files = image_files\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self,index) :\n",
    "        img = np.load(self.image_files[index])\n",
    "        label = os.path.basename(os.path.dirname(self.image_files[index]))\n",
    "        return self.transforms(img), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a28def70-daa4-478a-b1a5-87e065f08bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [   AsChannelFirst(2),\n",
    "        Resize((256,256)),\n",
    "        RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "        RandFlip(spatial_axis=0, prob=0.5),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [   AsChannelFirst(2),\n",
    "        Resize((256,256)),\n",
    "            ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "55b42063-1483-4aba-a931-66500e3f5060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = Sequence_Dataset(image_files=X_train,transforms=train_transforms)\n",
    "train_loader = DataLoader(train_ds,batch_size  = 50, shuffle=True, num_workers=8 , pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2452e22d-a15c-4182-9a91-52769fdf5a0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pytorch Lightining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6284b59-2650-47e9-a59c-c9bb2b79e26c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset Definition \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "68d3d5d2-9f35-4a00-b263-af929add395c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AsChannelFirst'>: Class `AsChannelFirst` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
      "  warn_deprecated(obj, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import numpy as np\n",
    "from monai.transforms import (\n",
    "    AsChannelFirst,\n",
    "    Compose,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    Resize\n",
    ")\n",
    "from monai.data import DataLoader\n",
    "\n",
    "def labeling(data) :\n",
    "    label = []\n",
    "    for path in data : \n",
    "        label.append(os.path.basename(os.path.dirname(path)))\n",
    "    return label\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [   AsChannelFirst(2),\n",
    "        Resize((256,256)),\n",
    "        RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "        RandFlip(spatial_axis=0, prob=0.5),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [   AsChannelFirst(2),\n",
    "        Resize((256,256)),\n",
    "            ]\n",
    ")\n",
    "    \n",
    "\n",
    "class Sequence_Dataset(torch.utils.data.Dataset) : \n",
    "    def __init__(self,image_files,label, transforms): \n",
    "        self.image_files = image_files\n",
    "        self.transforms = transforms\n",
    "        self.label = label\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self,index) :\n",
    "        img = np.load(self.image_files[index])\n",
    "        return self.transforms(img), self.label[index]\n",
    "\n",
    "class DataModule(pl.LightningDataModule) : \n",
    "    \n",
    "    def __init__(self, data_dir : list , batch_size : int ) : \n",
    "        \n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.__ = None\n",
    "        \n",
    "    def prepare_data(self) :\n",
    "        y = labeling(X)\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2,shuffle=True ,random_state=42,stratify=y)\n",
    "        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(X_train, y_train, test_size=0.2,shuffle=True ,random_state=42,stratify=y_train)\n",
    "    \n",
    "    def setup(self,stage : str) : \n",
    "        \n",
    "        if stage == \"fit\" : \n",
    "            self.train_ds =  Sequence_Dataset(self.X_train,self.y_train,train_transforms)\n",
    "            self.val_ds = Sequence_Dataset(self.X_val,self.y_val,val_transforms)\n",
    "            \n",
    "        if stage == \"test\" : \n",
    "            self.test_ds = Sequence_Dataset(self.X_test,self.y_test,val_transforms)\n",
    "            \n",
    "    def train_dataloader(self) :\n",
    "        \n",
    "        return DataLoader(self.train_ds, batch_size  = self.batch_size, shuffle=True, num_workers=8 , pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self) :\n",
    "        \n",
    "        return DataLoader(self.val_ds, batch_size  = self.batch_size, shuffle=True, num_workers=8 , pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self) :\n",
    "        \n",
    "        return DataLoader(self.test_ds, batch_size  = self.batch_size, shuffle=True, num_workers=8 , pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9e7b62bf-8b99-45bc-9a9f-e62437113480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dm = DataModule(X,1)\n",
    "dm.prepare_data()\n",
    "dm.setup(stage =\"fit\")\n",
    "A = next(iter(dm.train_dataloader()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da43b5-6a24-47c6-b332-8192d5a569d6",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1e8999ee-5480-45a8-81ae-e3079e7c042f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from monai.networks.nets import ResNet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x) : \n",
    "        self.model(x)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self._model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927e8205-a6e1-4752-9380-68c55e58caf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
